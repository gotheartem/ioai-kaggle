{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5562ce-eb4a-4f32-b351-3bdd2a7cced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985a2b9e-da41-4d51-baa8-d1e74ac4c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "dataset_name = \"tatsu-lab/alpaca\"  # можно заменить на локальный путь или huggingface dataset id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d708b089-da68-40bf-9010-1e9566424846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c0ce452bd7494584ec917e4b4b34a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Загрузка модели и токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    "    # llm_int8_threshold=6.0\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f08e3dd-f815-4ace-a69f-426677effb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Настройка LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # в зависимости от модели\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69eb2193-3898-463e-bcf0-5c29cff47399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Подготовка данных\n",
    "def formatting_func(example):\n",
    "    prompt = f\"<bos><start_of_turn>system\\n{example['instruction']}<end_of_turn>\\n<start_of_turn>user\\n{example['input']}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    full_text = prompt + example[\"output\"]\n",
    "    return {\"text\": full_text}\n",
    "\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "split_dataset = dataset.train_test_split(test_size=0.01, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "dataset = dataset.map(formatting_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895a1de3-8afe-4e2c-868b-abce0ec8d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = logits.argmax(-1)\n",
    "\n",
    "    # Поскольку perplexity принимает списки строк — декодируем\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Вычисляем perplexity\n",
    "    results = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"perplexity\": results[\"perplexity\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0401f03a-27af-4eb9-ac31-828d2c8049bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Настройка обучения\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_seq_length=512,\n",
    "    packing=False,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_steps=500,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    # fp16=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3cbf97-abc9-461a-a227-1f9f164d6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b603642c555472486dd8dfdbe2d26e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/51481 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0ab1b871334994a6779917fa09ca21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# 5. Тренировка\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=training_args,\n",
    "    compute_metrics=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae08b4b-33b3-4961-af68-f11b0c308731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1338' max='9651' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1338/9651 40:05 < 4:09:29, 0.56 it/s, Epoch 0.42/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.433800</td>\n",
       "      <td>1.339693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.272800</td>\n",
       "      <td>1.275633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.289500</td>\n",
       "      <td>1.210593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.268800</td>\n",
       "      <td>1.209696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.234200</td>\n",
       "      <td>1.200176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.202900</td>\n",
       "      <td>1.197046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.176700</td>\n",
       "      <td>1.190623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.258800</td>\n",
       "      <td>1.190975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.193200</td>\n",
       "      <td>1.190723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.252900</td>\n",
       "      <td>1.184475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.160300</td>\n",
       "      <td>1.186403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.209200</td>\n",
       "      <td>1.177970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.162200</td>\n",
       "      <td>1.179851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.141200</td>\n",
       "      <td>1.187638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.202100</td>\n",
       "      <td>1.180241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.162600</td>\n",
       "      <td>1.180248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.255300</td>\n",
       "      <td>1.176813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.188300</td>\n",
       "      <td>1.175240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.199900</td>\n",
       "      <td>1.170718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.158600</td>\n",
       "      <td>1.162344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.165500</td>\n",
       "      <td>1.170770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.206500</td>\n",
       "      <td>1.165295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.238200</td>\n",
       "      <td>1.166971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.208100</td>\n",
       "      <td>1.160327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.210700</td>\n",
       "      <td>1.157512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.197900</td>\n",
       "      <td>1.161760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25132c33-495b-472a-b8ea-da4fee438bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
